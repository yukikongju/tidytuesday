{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d65a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yukikongju/Projects/tidytuesday/financials_news_sentimentanalysis\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e9b9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import torch\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from torch import nn, optim\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de47b8b",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7518b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df = df[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d17cd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {'positive': 2, 'negative': 0, 'neutral': 1}\n",
    "y = df['Sentiment'].apply(lambda x: sentiment_dict.get(str(x))).tolist()\n",
    "X = df['Sentence'].tolist() # FIXME: should we split first, then vectorize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e1b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6601552",
   "metadata": {},
   "source": [
    "### Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f648ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Normalizer, self).__init__()\n",
    "        self.stop_words = stopwords.words('english')\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, sentences, labels=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sentences, labels=None):\n",
    "        return [self.normalize(sentence) for sentence in sentences]\n",
    "    \n",
    "    def normalize(self, sentence):\n",
    "        pass\n",
    "\n",
    "class LemmerNormalizer(Normalizer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LemmerNormalizer, self).__init__()\n",
    "        \n",
    "    def normalize(self, sentence):\n",
    "        words = []\n",
    "        for word in sentence.split(' '):\n",
    "            words.append(self.lemmatizer.lemmatize(word))\n",
    "        return ' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7d4c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NGramsVectorizer(BaseEstimator, TransformerMixin):  \n",
    "class NGramsVectorizer(BaseEstimator):    \n",
    "    \n",
    "    \n",
    "    def __init__(self, n_grams=2):\n",
    "        super(NGramsVectorizer, self).__init__()\n",
    "        self.n_grams = n_grams\n",
    "        self.vocab = None\n",
    "        self.word_dict = None\n",
    "    \n",
    "    def fit(self, sentences, labels=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sentences, labels):\n",
    "        # build vocab\n",
    "        self._build_vocab(sentences)\n",
    "        \n",
    "        # build word dict\n",
    "        self._build_word_dict()\n",
    "        \n",
    "        # get ngram \n",
    "        ngrams = []\n",
    "        for sentence, label in zip(sentences, labels):\n",
    "            sentence_grams = self._get_ngrams_from_sentence(sentence)\n",
    "            for gram in sentence_grams:\n",
    "                gram_idx = [self.word_dict.get(word) for word in gram]\n",
    "#                 ngrams.append((gram, label))\n",
    "                ngrams.append((gram_idx, label))\n",
    "                \n",
    "        return ngrams\n",
    "    \n",
    "    def _get_ngrams_from_sentence(self, sentence):\n",
    "        \"\"\" \n",
    "        >>> sentence = \"Report suggests that company should go bankrupt by the end of the quarter\"\n",
    "        >>> [['Report', 'suggests'], ['suggests', 'that'], ..,  ['the', 'quarter'] ]\n",
    "        \"\"\"\n",
    "        words = sentence.split(' ')\n",
    "        ngrams = [words[i:i+n] for i in range(0, len(words)-1)]\n",
    "        return ngrams\n",
    "        \n",
    "    \n",
    "    def _build_vocab(self, sentences):\n",
    "        self.vocab = set([word for sentence in sentences for word in sentence.split(' ')])\n",
    "        \n",
    "    \n",
    "    def _build_word_dict(self):\n",
    "        self.word_dict = { word: i for i, word in enumerate(self.vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3383c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, n = \"Report suggests that company should go bankrupt by the end of the quarter\", 2\n",
    "text = text.split(' ')\n",
    "ngrams = [text[i:i+n] for i in range(0, len(text)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ec99f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = NGramsVectorizer()\n",
    "ngrams_vect = vectorizer.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a459adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af73cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c2a18c8",
   "metadata": {},
   "source": [
    "### Split data into Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50e67745",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_x, ngrams_y = [], []\n",
    "for ngram_x, ngram_y in ngrams_vect:\n",
    "    ngrams_x.append(ngram_x)\n",
    "    ngrams_y.append(ngram_y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(ngrams_x, ngrams_y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc813edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6cc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422a75ad",
   "metadata": {},
   "source": [
    "### Train Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "598f1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6203052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.15      0.04        48\n",
      "           1       0.88      0.61      0.72      2051\n",
      "           2       0.14      0.33      0.19       265\n",
      "\n",
      "    accuracy                           0.57      2364\n",
      "   macro avg       0.35      0.36      0.32      2364\n",
      "weighted avg       0.78      0.57      0.65      2364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(XGBClassifier(), x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a99bf730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.60      0.75      2364\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      2364\n",
      "   macro avg       0.33      0.20      0.25      2364\n",
      "weighted avg       1.00      0.60      0.75      2364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(GaussianNB(), x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "79fe1479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.14      0.15       367\n",
      "           1       0.60      0.62      0.61      1374\n",
      "           2       0.28      0.29      0.28       623\n",
      "\n",
      "    accuracy                           0.46      2364\n",
      "   macro avg       0.35      0.35      0.35      2364\n",
      "weighted avg       0.45      0.46      0.45      2364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(DecisionTreeClassifier(), x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8c1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90693833",
   "metadata": {},
   "source": [
    "### Train Basic Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a18e2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fct1 = nn.Linear(num_inputs, 64)\n",
    "        self.fct2 = nn.Linear(64, num_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fct1(x))\n",
    "        x = torch.sigmoid(self.fct2(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94bc3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(n_epochs, model, loss_fn, optim, x_train, y_train):\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        for word_vec, label in zip(x_train, y_train):\n",
    "            word_vec = torch.tensor(word_vec, dtype=torch.float).unsqueeze(0)\n",
    "            output = model(word_vec)\n",
    "            loss = loss_fn(output, torch.tensor([label]))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        losses.append(loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss {loss}\")\n",
    "    return losses\n",
    "\n",
    "def prediction(model, x_test, y_test):\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for word_vec in x_test:\n",
    "            word_vec = torch.tensor(word_vec, dtype=torch.float).unsqueeze(0)\n",
    "            output = model(word_vec)\n",
    "            _, label_pred = torch.max(output, dim=1)\n",
    "#             print(output, label_pred)\n",
    "            y_pred.append(label_pred.item())\n",
    "    \n",
    "    print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cce3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04a5c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss -0.8750810027122498\n",
      "Epoch 10, Loss -0.985752522945404\n",
      "Epoch 20, Loss -0.9921588897705078\n",
      "Epoch 30, Loss -0.9945111274719238\n",
      "Epoch 40, Loss -0.9969218373298645\n",
      "Epoch 50, Loss -0.9975041747093201\n",
      "Epoch 60, Loss -0.9978916049003601\n",
      "Epoch 70, Loss -0.9981833100318909\n",
      "Epoch 80, Loss -0.9984081387519836\n",
      "Epoch 90, Loss -0.9985804557800293\n"
     ]
    }
   ],
   "source": [
    "n_epochs, n = 100, 2\n",
    "num_classes = len(df['Sentiment'].unique())\n",
    "model = SimpleNN(num_inputs=n, num_outputs=num_classes)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "losses = training(n_epochs, model, loss_fn, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "195cc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.60      0.75      2364\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      2364\n",
      "   macro avg       0.33      0.20      0.25      2364\n",
      "weighted avg       1.00      0.60      0.75      2364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yukikongju/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924f0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b098d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
