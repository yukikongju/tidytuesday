{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc30913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a49b8b",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d307477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5f824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5842"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a66b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa8fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     3130\n",
      "positive    1852\n",
      "negative     860\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d96555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea6833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "353086d5",
   "metadata": {},
   "source": [
    "### Vectorize Sentence with Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d91e109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCATopicVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \"\"\" \n",
    "    Transform co-occurence matrix / TF-IDF into topic vectors \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> documents = [\"I am writing\", \"The word is short\"]\n",
    "    >>> topic_vectorizer = PCATopicVectorizer(TfidfVectorizer(), n_topics = 6)\n",
    "    >>> df = topic_vectorizer.fit_transform(documents)\n",
    "    >>>             topic0  topic1  topic2  topic3  topic4  topic5\n",
    "    ...     rather  0.0044  0.0951 -0.1192  0.2258 -0.1503 -0.0067\n",
    "    >>> df size: num words x num topics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vectorizer, n_topics):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.n_topics = n_topics\n",
    "        self.pca = PCA(n_components=n_topics)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, documents):\n",
    "        # get co-occurence matrix with vectorizer\n",
    "        documents_vectorized = self.vectorizer.fit_transform(documents)\n",
    "        occ_mat = documents_vectorized.toarray()\n",
    "        word_dict = self.vectorizer.vocabulary_\n",
    "        vocab = sorted(self.vectorizer.vocabulary_.keys())\n",
    "\n",
    "        # get topic vetor with pca (dimension reduction)\n",
    "        pca_topic_vectors = self.pca.fit_transform(occ_mat)\n",
    "#         weights = pd.DataFrame(self.pca.components_.round(4), columns=word_dict, \n",
    "#                 index=[f'topic{i}' for i in range(self.n_topics)])\n",
    "#         return weights.T\n",
    "        return pd.DataFrame(pca_topic_vectors)\n",
    "        \n",
    "class TruncatedSVDTopicVectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vectorizer, n_topics):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.n_topics = n_topics\n",
    "        self.svd = TruncatedSVD(n_components=n_topics)\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, documents):\n",
    "        # get co-occurence matrix with vectorizer\n",
    "        documents_vectorized = self.vectorizer.fit_transform(documents)\n",
    "        occ_mat = documents_vectorized.toarray()\n",
    "        word_dict = self.vectorizer.vocabulary_\n",
    "        vocab = sorted(self.vectorizer.vocabulary_.keys())\n",
    "\n",
    "        # get topic vetor with pca (dimension reduction)\n",
    "        topic_vectors = self.svd.fit_transform(occ_mat)\n",
    "#         weights = pd.DataFrame(self.svd.components_.round(4), columns=word_dict, \n",
    "#                 index=[f'topic{i}' for i in range(self.n_topics)])\n",
    "#         return weights.T\n",
    "        return pd.DataFrame(topic_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e29431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Normalizer, self).__init__()\n",
    "#         self.stop_words = stopwords.words('english')\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, sentences, labels=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sentences):\n",
    "        return [self.normalize(sentence) for sentence in sentences]\n",
    "    \n",
    "    def normalize(self, sentence):\n",
    "        pass\n",
    "    \n",
    "class LemmerNormalizer(Normalizer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LemmerNormalizer, self).__init__()\n",
    "        \n",
    "    def normalize(self, sentence):\n",
    "        words = []\n",
    "        for word in sentence.split(' '):\n",
    "            words.append(self.lemmatizer.lemmatize(word))\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6f38b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080547</td>\n",
       "      <td>-0.047560</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.023299</td>\n",
       "      <td>-0.036874</td>\n",
       "      <td>-0.017216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.044806</td>\n",
       "      <td>-0.084806</td>\n",
       "      <td>0.052420</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.010859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088171</td>\n",
       "      <td>0.146225</td>\n",
       "      <td>0.075232</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>-0.026032</td>\n",
       "      <td>0.075103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.086496</td>\n",
       "      <td>-0.103460</td>\n",
       "      <td>-0.057106</td>\n",
       "      <td>-0.022553</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.058007</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>-0.042545</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>-0.040885</td>\n",
       "      <td>-0.022565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>-0.068024</td>\n",
       "      <td>-0.056550</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>-0.053824</td>\n",
       "      <td>-0.054168</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.026409</td>\n",
       "      <td>0.018824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>-0.079462</td>\n",
       "      <td>-0.006293</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.034532</td>\n",
       "      <td>0.021192</td>\n",
       "      <td>-0.028905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0.196840</td>\n",
       "      <td>-0.056173</td>\n",
       "      <td>-0.043662</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>-0.146317</td>\n",
       "      <td>0.023787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>-0.059301</td>\n",
       "      <td>-0.037596</td>\n",
       "      <td>0.066079</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>-0.018018</td>\n",
       "      <td>-0.048651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5\n",
       "0    -0.080547 -0.047560 -0.002001 -0.023299 -0.036874 -0.017216\n",
       "1    -0.044806 -0.084806  0.052420  0.016438  0.024691  0.010859\n",
       "2     0.088171  0.146225  0.075232  0.089299 -0.026032  0.075103\n",
       "3     0.002422  0.086496 -0.103460 -0.057106 -0.022553  0.010245\n",
       "4    -0.058007  0.031016 -0.042545  0.002675 -0.040885 -0.022565\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "5837 -0.068024 -0.056550  0.030989  0.007151  0.003565  0.000157\n",
       "5838 -0.053824 -0.054168  0.022841  0.013444 -0.026409  0.018824\n",
       "5839 -0.079462 -0.006293 -0.044158 -0.034532  0.021192 -0.028905\n",
       "5840  0.196840 -0.056173 -0.043662  0.009098 -0.146317  0.023787\n",
       "5841 -0.059301 -0.037596  0.066079 -0.001418 -0.018018 -0.048651\n",
       "\n",
       "[5842 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = PCATopicVectorizer(TfidfVectorizer(), 6)\n",
    "vectorizer.fit_transform(df['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b469ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer', LemmerNormalizer()),\n",
    "    ('vectorizer', PCATopicVectorizer(TfidfVectorizer(), 8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b02da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "132b15d7",
   "metadata": {},
   "source": [
    "### Split Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c53ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {'positive': 2, 'negative': 0, 'neutral': 1}\n",
    "y = df['Sentiment'].apply(lambda x: sentiment_dict.get(str(x))).tolist()\n",
    "X = pipeline.fit_transform(df['Sentence']) # FIXME: should I split first, then vectorize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0798b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.082162</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>-0.006066</td>\n",
       "      <td>-0.038137</td>\n",
       "      <td>-0.033010</td>\n",
       "      <td>-0.005078</td>\n",
       "      <td>-0.003851</td>\n",
       "      <td>-0.047816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045003</td>\n",
       "      <td>-0.088103</td>\n",
       "      <td>0.051362</td>\n",
       "      <td>0.019791</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>-0.005406</td>\n",
       "      <td>0.047180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.149550</td>\n",
       "      <td>0.085529</td>\n",
       "      <td>0.089502</td>\n",
       "      <td>-0.038040</td>\n",
       "      <td>0.041604</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.164709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.113428</td>\n",
       "      <td>-0.117405</td>\n",
       "      <td>-0.059986</td>\n",
       "      <td>-0.011854</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>-0.009274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.059110</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>-0.036604</td>\n",
       "      <td>-0.008433</td>\n",
       "      <td>-0.061202</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.039707</td>\n",
       "      <td>-0.011427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>-0.070881</td>\n",
       "      <td>-0.058412</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>-0.011128</td>\n",
       "      <td>-0.018385</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>-0.050023</td>\n",
       "      <td>-0.055133</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>0.021596</td>\n",
       "      <td>-0.057037</td>\n",
       "      <td>-0.007175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>-0.080865</td>\n",
       "      <td>-0.009503</td>\n",
       "      <td>-0.046569</td>\n",
       "      <td>-0.030033</td>\n",
       "      <td>0.016156</td>\n",
       "      <td>-0.034531</td>\n",
       "      <td>-0.003830</td>\n",
       "      <td>0.054906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>0.198316</td>\n",
       "      <td>-0.054323</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.031664</td>\n",
       "      <td>-0.112926</td>\n",
       "      <td>0.078606</td>\n",
       "      <td>-0.117437</td>\n",
       "      <td>-0.163252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>-0.059852</td>\n",
       "      <td>-0.032250</td>\n",
       "      <td>0.067551</td>\n",
       "      <td>-0.007399</td>\n",
       "      <td>-0.044696</td>\n",
       "      <td>-0.063039</td>\n",
       "      <td>0.108012</td>\n",
       "      <td>-0.013783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.082162 -0.049403 -0.006066 -0.038137 -0.033010 -0.005078 -0.003851   \n",
       "1    -0.045003 -0.088103  0.051362  0.019791  0.021702  0.008366 -0.005406   \n",
       "2     0.100500  0.149550  0.085529  0.089502 -0.038040  0.041604  0.036000   \n",
       "3     0.003943  0.113428 -0.117405 -0.059986 -0.011854  0.005935  0.033674   \n",
       "4    -0.059110  0.031338 -0.036604 -0.008433 -0.061202  0.003634  0.039707   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5837 -0.070881 -0.058412  0.028664  0.006910 -0.011128 -0.018385  0.043639   \n",
       "5838 -0.050023 -0.055133  0.022763  0.008235 -0.016335  0.021596 -0.057037   \n",
       "5839 -0.080865 -0.009503 -0.046569 -0.030033  0.016156 -0.034531 -0.003830   \n",
       "5840  0.198316 -0.054323 -0.049095 -0.031664 -0.112926  0.078606 -0.117437   \n",
       "5841 -0.059852 -0.032250  0.067551 -0.007399 -0.044696 -0.063039  0.108012   \n",
       "\n",
       "             7  \n",
       "0    -0.047816  \n",
       "1     0.047180  \n",
       "2     0.164709  \n",
       "3    -0.009274  \n",
       "4    -0.011427  \n",
       "...        ...  \n",
       "5837  0.000239  \n",
       "5838 -0.007175  \n",
       "5839  0.054906  \n",
       "5840 -0.163252  \n",
       "5841 -0.013783  \n",
       "\n",
       "[5842 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3141f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d51aed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753 1753\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2ec36",
   "metadata": {},
   "source": [
    "### Resample with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22770d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2197\n",
      "2    1275\n",
      "0     617\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e52181dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8df20543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2197\n",
      "1    2197\n",
      "2    2197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(y_train_res).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e764318e",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa8b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a516f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.14      0.17       360\n",
      "           1       0.67      0.65      0.66       954\n",
      "           2       0.43      0.56      0.49       439\n",
      "\n",
      "    accuracy                           0.52      1753\n",
      "   macro avg       0.43      0.45      0.44      1753\n",
      "weighted avg       0.51      0.52      0.52      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(XGBClassifier(), x_train_res, x_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "012fe193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.26      0.36       554\n",
      "           1       0.84      0.66      0.74      1179\n",
      "           2       0.02      0.50      0.03        20\n",
      "\n",
      "    accuracy                           0.53      1753\n",
      "   macro avg       0.48      0.47      0.38      1753\n",
      "weighted avg       0.75      0.53      0.61      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(SGDClassifier(), x_train_res, x_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "481a6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.23      0.26       323\n",
      "           1       0.64      0.71      0.67       833\n",
      "           2       0.47      0.46      0.47       597\n",
      "\n",
      "    accuracy                           0.54      1753\n",
      "   macro avg       0.47      0.47      0.47      1753\n",
      "weighted avg       0.52      0.54      0.53      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(GaussianNB(), x_train_res, x_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1635c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35       418\n",
      "           1       0.66      0.72      0.69       855\n",
      "           2       0.38      0.45      0.41       480\n",
      "\n",
      "    accuracy                           0.54      1753\n",
      "   macro avg       0.50      0.48      0.48      1753\n",
      "weighted avg       0.54      0.54      0.53      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(LogisticRegression(), x_train_res, x_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "127a7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.11      0.15       441\n",
      "           1       0.52      0.58      0.55       834\n",
      "           2       0.39      0.47      0.43       478\n",
      "\n",
      "    accuracy                           0.43      1753\n",
      "   macro avg       0.37      0.39      0.37      1753\n",
      "weighted avg       0.41      0.43      0.42      1753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_model_performance(DecisionTreeClassifier(), x_train_res, x_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224c23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abdc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae702d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca3a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344d82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
